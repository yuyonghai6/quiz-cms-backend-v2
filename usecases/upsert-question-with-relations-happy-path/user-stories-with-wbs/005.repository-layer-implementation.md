# US-005: Repository Layer Implementation

## Story Overview
**As a** developer
**I want** clean repository abstractions with MongoDB implementations
**So that** the domain layer remains isolated from persistence concerns while supporting upsert operations and transactions

## Business Value
- Maintains clean architecture with separated concerns
- Enables easy testing through repository interfaces
- Supports MongoDB-specific operations efficiently
- Provides foundation for transaction support

## Work Breakdown Structure (WBS)

### 1. Repository Interface Design (Port OUT)
**Estimated Effort**: 1 day
**Priority**: High
**Dependencies**: US-002 QuestionAggregate, US-006 Supporting Aggregates

#### Tasks:
- [ ] **1.1** Define QuestionRepository interface in domain layer
- [ ] **1.2** Define QuestionTaxonomyRelationshipRepository interface
- [ ] **1.3** Create repository method contracts using Result<T>
- [ ] **1.4** Add comprehensive Javadoc documentation
- [ ] **1.5** Define exception handling strategies

#### Implementation Details:
```java
// Location: internal-layer/question-bank/src/main/java/com/quizfun/questionbank/domain/ports/out/QuestionRepository.java
public interface QuestionRepository {
    Result<QuestionAggregate> upsertBySourceQuestionId(QuestionAggregate aggregate);
    Result<Optional<QuestionAggregate>> findBySourceQuestionId(Long userId, Long questionBankId, String sourceQuestionId);
    Result<List<QuestionAggregate>> findByQuestionBank(Long userId, Long questionBankId);
    Result<Void> delete(ObjectId questionId);
}

// Location: internal-layer/question-bank/src/main/java/com/quizfun/questionbank/domain/ports/out/QuestionTaxonomyRelationshipRepository.java
public interface QuestionTaxonomyRelationshipRepository {
    Result<Void> replaceRelationshipsForQuestion(ObjectId questionId, List<QuestionTaxonomyRelationshipAggregate> relationships);
    Result<List<QuestionTaxonomyRelationshipAggregate>> findByQuestionId(ObjectId questionId);
    Result<Void> deleteByQuestionId(ObjectId questionId);
}
```

#### Acceptance Criteria:
- Repository interfaces in domain layer as Port OUT contracts
- Use Result<T> for consistent error handling
- Methods follow domain language and concepts
- Comprehensive documentation provided

#### Test Requirements:
- [ ] Interface contract verification tests
- [ ] Method signature validation tests

---

### 2. MongoDB Document Mapping Classes
**Estimated Effort**: 1 day
**Priority**: High
**Dependencies**: Task 1 complete

#### Tasks:
- [ ] **2.1** Create QuestionDocument mapping class
- [ ] **2.2** Create QuestionTaxonomyRelationshipDocument mapping class
- [ ] **2.3** Implement aggregate-to-document mapping
- [ ] **2.4** Implement document-to-aggregate mapping
- [ ] **2.5** Add JSON serialization annotations
- [ ] **2.6** Handle MongoDB-specific ObjectId mapping

#### Implementation Details:
```java
// Location: internal-layer/question-bank/src/main/java/com/quizfun/questionbank/infrastructure/persistence/documents/QuestionDocument.java
@Document(collection = "questions")
public class QuestionDocument {
    @Id
    private ObjectId id;

    @Field("user_id")
    private Long userId;

    @Field("question_bank_id")
    private Long questionBankId;

    @Field("source_question_id")
    private String sourceQuestionId;

    @Field("question_type")
    private String questionType;

    private String title;
    private String content;
    private Integer points;
    private String status;

    @Field("mcq_data")
    private McqDataDocument mcqData;

    @Field("essay_data")
    private EssayDataDocument essayData;

    @Field("true_false_data")
    private TrueFalseDataDocument trueFalseData;

    @Field("created_at")
    private Instant createdAt;

    @Field("updated_at")
    private Instant updatedAt;

    public static QuestionDocument fromAggregate(QuestionAggregate aggregate) {
        var document = new QuestionDocument();
        document.id = aggregate.getId();
        document.userId = aggregate.getUserId();
        document.questionBankId = aggregate.getQuestionBankId();
        document.sourceQuestionId = aggregate.getSourceQuestionId();
        document.questionType = aggregate.getQuestionType().getValue();
        document.title = aggregate.getTitle();
        document.content = aggregate.getContent();
        document.points = aggregate.getPoints();
        document.status = aggregate.getStatus();
        document.createdAt = aggregate.getCreatedAt();
        document.updatedAt = aggregate.getUpdatedAt();

        // Map type-specific data
        if (aggregate.getMcqData() != null) {
            document.mcqData = McqDataDocument.fromValueObject(aggregate.getMcqData());
        }
        if (aggregate.getEssayData() != null) {
            document.essayData = EssayDataDocument.fromValueObject(aggregate.getEssayData());
        }
        if (aggregate.getTrueFalseData() != null) {
            document.trueFalseData = TrueFalseDataDocument.fromValueObject(aggregate.getTrueFalseData());
        }

        return document;
    }

    public QuestionAggregate toAggregate() {
        var questionType = QuestionType.valueOf(this.questionType.toUpperCase());

        var aggregate = QuestionAggregate.createNew(
            this.userId,
            this.questionBankId,
            this.sourceQuestionId,
            questionType,
            this.title,
            this.content,
            this.points
        );

        // Set MongoDB ID
        aggregate.setId(this.id);

        // Set timestamps
        aggregate.setCreatedAt(this.createdAt);
        aggregate.setUpdatedAt(this.updatedAt);

        // Set type-specific data
        if (this.mcqData != null) {
            aggregate.setMcqData(this.mcqData.toValueObject());
        }
        if (this.essayData != null) {
            aggregate.setEssayData(this.essayData.toValueObject());
        }
        if (this.trueFalseData != null) {
            aggregate.setTrueFalseData(this.trueFalseData.toValueObject());
        }

        return aggregate;
    }
}
```

#### Acceptance Criteria:
- Document classes map to MongoDB collections
- Bidirectional mapping between aggregates and documents
- Proper field mapping with MongoDB annotations
- Type-specific data handled correctly

#### Test Requirements:
- [ ] Aggregate-to-document mapping tests
- [ ] Document-to-aggregate mapping tests
- [ ] JSON serialization tests
- [ ] Type-specific data mapping tests

---

### 3. MongoDB Question Repository Implementation
**Estimated Effort**: 1.5 days
**Priority**: High
**Dependencies**: Task 2 complete

#### Tasks:
- [ ] **3.1** Implement MongoQuestionRepository class
- [ ] **3.2** Implement upsert logic using source_question_id
- [ ] **3.3** Add find operations with user/questionBank scoping
- [ ] **3.4** Implement proper error handling and logging
- [ ] **3.5** Add performance optimization for common queries
- [ ] **3.6** Handle MongoDB-specific exceptions

#### Implementation Details:
```java
// Location: internal-layer/question-bank/src/main/java/com/quizfun/questionbank/infrastructure/persistence/repositories/MongoQuestionRepository.java
@Repository
public class MongoQuestionRepository implements QuestionRepository {

    private static final Logger logger = LoggerFactory.getLogger(MongoQuestionRepository.class);
    private final MongoTemplate mongoTemplate;

    public MongoQuestionRepository(MongoTemplate mongoTemplate) {
        this.mongoTemplate = mongoTemplate;
    }

    @Override
    public Result<QuestionAggregate> upsertBySourceQuestionId(QuestionAggregate aggregate) {
        try {
            logger.debug("Upserting question with source ID: {} for user: {} and question bank: {}",
                        aggregate.getSourceQuestionId(), aggregate.getUserId(), aggregate.getQuestionBankId());

            // Check if question exists
            var query = Query.query(Criteria
                .where("user_id").is(aggregate.getUserId())
                .and("question_bank_id").is(aggregate.getQuestionBankId())
                .and("source_question_id").is(aggregate.getSourceQuestionId()));

            var existingDocument = mongoTemplate.findOne(query, QuestionDocument.class);

            if (existingDocument != null) {
                // Update existing question - preserve MongoDB _id
                aggregate.setId(existingDocument.getId());
                aggregate.updateTimestamp();
                logger.debug("Updating existing question with MongoDB ID: {}", existingDocument.getId());
            } else {
                // Create new question
                aggregate.setCreationTimestamp();
                logger.debug("Creating new question");
            }

            // Convert to document and save
            var document = QuestionDocument.fromAggregate(aggregate);
            var savedDocument = mongoTemplate.save(document);

            logger.debug("Successfully upserted question with MongoDB ID: {}", savedDocument.getId());

            return Result.success(savedDocument.toAggregate());

        } catch (DataAccessException ex) {
            logger.error("Database error during question upsert for source ID: {}",
                        aggregate.getSourceQuestionId(), ex);
            return Result.failure("DATABASE_ERROR", "Failed to upsert question: " + ex.getMessage());

        } catch (Exception ex) {
            logger.error("Unexpected error during question upsert for source ID: {}",
                        aggregate.getSourceQuestionId(), ex);
            return Result.failure("UPSERT_ERROR", "Unexpected error during question upsert: " + ex.getMessage());
        }
    }

    @Override
    public Result<Optional<QuestionAggregate>> findBySourceQuestionId(Long userId, Long questionBankId, String sourceQuestionId) {
        try {
            logger.debug("Finding question by source ID: {} for user: {} and question bank: {}",
                        sourceQuestionId, userId, questionBankId);

            var query = Query.query(Criteria
                .where("user_id").is(userId)
                .and("question_bank_id").is(questionBankId)
                .and("source_question_id").is(sourceQuestionId));

            var document = mongoTemplate.findOne(query, QuestionDocument.class);

            if (document != null) {
                logger.debug("Found question with MongoDB ID: {}", document.getId());
                return Result.success(Optional.of(document.toAggregate()));
            } else {
                logger.debug("No question found with source ID: {}", sourceQuestionId);
                return Result.success(Optional.empty());
            }

        } catch (DataAccessException ex) {
            logger.error("Database error during question find for source ID: {}", sourceQuestionId, ex);
            return Result.failure("DATABASE_ERROR", "Failed to find question: " + ex.getMessage());

        } catch (Exception ex) {
            logger.error("Unexpected error during question find for source ID: {}", sourceQuestionId, ex);
            return Result.failure("FIND_ERROR", "Unexpected error during question find: " + ex.getMessage());
        }
    }

    @Override
    public Result<List<QuestionAggregate>> findByQuestionBank(Long userId, Long questionBankId) {
        try {
            logger.debug("Finding questions for user: {} and question bank: {}", userId, questionBankId);

            var query = Query.query(Criteria
                .where("user_id").is(userId)
                .and("question_bank_id").is(questionBankId));

            var documents = mongoTemplate.find(query, QuestionDocument.class);
            var aggregates = documents.stream()
                .map(QuestionDocument::toAggregate)
                .collect(Collectors.toList());

            logger.debug("Found {} questions for user: {} and question bank: {}",
                        aggregates.size(), userId, questionBankId);

            return Result.success(aggregates);

        } catch (DataAccessException ex) {
            logger.error("Database error during questions find for user: {} and question bank: {}",
                        userId, questionBankId, ex);
            return Result.failure("DATABASE_ERROR", "Failed to find questions: " + ex.getMessage());

        } catch (Exception ex) {
            logger.error("Unexpected error during questions find for user: {} and question bank: {}",
                        userId, questionBankId, ex);
            return Result.failure("FIND_ERROR", "Unexpected error during questions find: " + ex.getMessage());
        }
    }

    @Override
    public Result<Void> delete(ObjectId questionId) {
        try {
            logger.debug("Deleting question with MongoDB ID: {}", questionId);

            var query = Query.query(Criteria.where("_id").is(questionId));
            var deleteResult = mongoTemplate.remove(query, QuestionDocument.class);

            if (deleteResult.getDeletedCount() > 0) {
                logger.debug("Successfully deleted question with MongoDB ID: {}", questionId);
                return Result.success(null);
            } else {
                logger.warn("No question found to delete with MongoDB ID: {}", questionId);
                return Result.failure("QUESTION_NOT_FOUND", "Question not found for deletion");
            }

        } catch (DataAccessException ex) {
            logger.error("Database error during question deletion for ID: {}", questionId, ex);
            return Result.failure("DATABASE_ERROR", "Failed to delete question: " + ex.getMessage());

        } catch (Exception ex) {
            logger.error("Unexpected error during question deletion for ID: {}", questionId, ex);
            return Result.failure("DELETE_ERROR", "Unexpected error during question deletion: " + ex.getMessage());
        }
    }
}
```

#### Acceptance Criteria:
- Upsert logic works correctly for create and update scenarios
- User and question bank scoping enforced in all queries
- Comprehensive error handling with Result<T> pattern
- Performance optimized for common query patterns
- Proper logging for debugging and monitoring

#### Test Requirements:
- [ ] Unit test: upsert new question scenario
- [ ] Unit test: upsert existing question scenario
- [ ] Unit test: find by source question ID
- [ ] Unit test: find by question bank
- [ ] Unit test: delete question
- [ ] Integration test: with TestContainers MongoDB

---

### 4. MongoDB Relationship Repository Implementation
**Estimated Effort**: 1 day
**Priority**: High
**Dependencies**: Task 3 complete

#### Tasks:
- [ ] **4.1** Implement MongoQuestionTaxonomyRelationshipRepository
- [ ] **4.2** Implement replace relationships logic (delete + insert)
- [ ] **4.3** Add bulk operation optimization
- [ ] **4.4** Handle transaction support preparation
- [ ] **4.5** Add comprehensive error handling

#### Implementation Details:
```java
// Location: internal-layer/question-bank/src/main/java/com/quizfun/questionbank/infrastructure/persistence/repositories/MongoQuestionTaxonomyRelationshipRepository.java
@Repository
public class MongoQuestionTaxonomyRelationshipRepository implements QuestionTaxonomyRelationshipRepository {

    private static final Logger logger = LoggerFactory.getLogger(MongoQuestionTaxonomyRelationshipRepository.class);
    private final MongoTemplate mongoTemplate;

    public MongoQuestionTaxonomyRelationshipRepository(MongoTemplate mongoTemplate) {
        this.mongoTemplate = mongoTemplate;
    }

    @Override
    public Result<Void> replaceRelationshipsForQuestion(ObjectId questionId,
                                                        List<QuestionTaxonomyRelationshipAggregate> relationships) {
        try {
            logger.debug("Replacing taxonomy relationships for question ID: {} with {} relationships",
                        questionId, relationships.size());

            // Step 1: Delete existing relationships for this question
            var deleteQuery = Query.query(Criteria.where("question_id").is(questionId));
            var deleteResult = mongoTemplate.remove(deleteQuery, "question_taxonomy_relationships");

            logger.debug("Deleted {} existing relationships for question ID: {}",
                        deleteResult.getDeletedCount(), questionId);

            // Step 2: Insert new relationships (if any)
            if (!relationships.isEmpty()) {
                var documents = relationships.stream()
                    .map(QuestionTaxonomyRelationshipDocument::fromAggregate)
                    .collect(Collectors.toList());

                mongoTemplate.insertAll(documents);

                logger.debug("Inserted {} new relationships for question ID: {}",
                            documents.size(), questionId);
            }

            logger.debug("Successfully replaced taxonomy relationships for question ID: {}", questionId);
            return Result.success(null);

        } catch (DataAccessException ex) {
            logger.error("Database error during relationship replacement for question ID: {}", questionId, ex);
            return Result.failure("DATABASE_ERROR",
                                 "Failed to replace taxonomy relationships: " + ex.getMessage());

        } catch (Exception ex) {
            logger.error("Unexpected error during relationship replacement for question ID: {}", questionId, ex);
            return Result.failure("RELATIONSHIP_ERROR",
                                 "Unexpected error during relationship replacement: " + ex.getMessage());
        }
    }

    @Override
    public Result<List<QuestionTaxonomyRelationshipAggregate>> findByQuestionId(ObjectId questionId) {
        try {
            logger.debug("Finding taxonomy relationships for question ID: {}", questionId);

            var query = Query.query(Criteria.where("question_id").is(questionId));
            var documents = mongoTemplate.find(query, QuestionTaxonomyRelationshipDocument.class);

            var aggregates = documents.stream()
                .map(QuestionTaxonomyRelationshipDocument::toAggregate)
                .collect(Collectors.toList());

            logger.debug("Found {} relationships for question ID: {}", aggregates.size(), questionId);
            return Result.success(aggregates);

        } catch (DataAccessException ex) {
            logger.error("Database error during relationship find for question ID: {}", questionId, ex);
            return Result.failure("DATABASE_ERROR",
                                 "Failed to find taxonomy relationships: " + ex.getMessage());

        } catch (Exception ex) {
            logger.error("Unexpected error during relationship find for question ID: {}", questionId, ex);
            return Result.failure("FIND_ERROR",
                                 "Unexpected error during relationship find: " + ex.getMessage());
        }
    }

    @Override
    public Result<Void> deleteByQuestionId(ObjectId questionId) {
        try {
            logger.debug("Deleting all taxonomy relationships for question ID: {}", questionId);

            var query = Query.query(Criteria.where("question_id").is(questionId));
            var deleteResult = mongoTemplate.remove(query, "question_taxonomy_relationships");

            logger.debug("Deleted {} relationships for question ID: {}",
                        deleteResult.getDeletedCount(), questionId);

            return Result.success(null);

        } catch (DataAccessException ex) {
            logger.error("Database error during relationship deletion for question ID: {}", questionId, ex);
            return Result.failure("DATABASE_ERROR",
                                 "Failed to delete taxonomy relationships: " + ex.getMessage());

        } catch (Exception ex) {
            logger.error("Unexpected error during relationship deletion for question ID: {}", questionId, ex);
            return Result.failure("DELETE_ERROR",
                                 "Unexpected error during relationship deletion: " + ex.getMessage());
        }
    }
}
```

#### Acceptance Criteria:
- Replace operation atomic (delete all + insert all)
- Bulk operations optimized for performance
- Comprehensive error handling and logging
- Support for empty relationship lists
- Proper document mapping

#### Test Requirements:
- [ ] Unit test: replace relationships functionality
- [ ] Unit test: find relationships by question ID
- [ ] Unit test: delete relationships by question ID
- [ ] Unit test: empty relationships handling
- [ ] Integration test: with TestContainers MongoDB

---

### 5. Repository Integration and Testing
**Estimated Effort**: 0.5 days
**Priority**: Medium
**Dependencies**: Tasks 3, 4 complete

#### Tasks:
- [ ] **5.1** Create comprehensive integration tests
- [ ] **5.2** Add repository performance benchmarks
- [ ] **5.3** Validate Spring configuration
- [ ] **5.4** Test error scenarios
- [ ] **5.5** Verify transaction readiness

#### Implementation Details:
```java
// Location: internal-layer/question-bank/src/test/java/com/quizfun/questionbank/infrastructure/persistence/QuestionRepositoryIntegrationTest.java
@SpringBootTest
@Import(TestcontainersConfig.class)
class QuestionRepositoryIntegrationTest extends BaseTestConfiguration {

    @Autowired
    private QuestionRepository questionRepository;

    @Autowired
    private QuestionTaxonomyRelationshipRepository relationshipRepository;

    @Test
    @DisplayName("Should upsert question and relationships together")
    void shouldUpsertQuestionAndRelationshipsTogether() {
        // Given
        var aggregate = createTestQuestionAggregate();
        var relationships = createTestRelationships();

        // When - Upsert question
        var questionResult = questionRepository.upsertBySourceQuestionId(aggregate);

        // Then
        assertThat(questionResult.isSuccess()).isTrue();
        var savedAggregate = questionResult.getValue();
        assertThat(savedAggregate.getId()).isNotNull();

        // When - Add relationships
        var relationshipResult = relationshipRepository.replaceRelationshipsForQuestion(
            savedAggregate.getId(), relationships);

        // Then
        assertThat(relationshipResult.isSuccess()).isTrue();

        // Verify relationships exist
        var findResult = relationshipRepository.findByQuestionId(savedAggregate.getId());
        assertThat(findResult.isSuccess()).isTrue();
        assertThat(findResult.getValue()).hasSize(relationships.size());
    }
}
```

## Acceptance Criteria Summary

### Functional Requirements
- [ ] Repository interfaces provide clean abstractions in domain layer
- [ ] MongoDB implementations handle all CRUD operations correctly
- [ ] Upsert logic works for both create and update scenarios
- [ ] Error handling returns Result<T> with appropriate error codes
- [ ] Document mapping preserves all aggregate data integrity

### Non-Functional Requirements
- [ ] Repository operations complete within 100ms for typical data
- [ ] Memory usage <50MB for repository operations
- [ ] Thread-safe repository implementations
- [ ] Code coverage >85% for repository logic

### Definition of Done
- [ ] All repository interfaces and implementations complete
- [ ] Document mapping classes with bidirectional conversion
- [ ] Comprehensive unit and integration tests
- [ ] Performance benchmarks established
- [ ] Error handling validated for all scenarios
- [ ] Code review completed

## Dependencies and Risks

### Dependencies
- US-002 QuestionAggregate with all business logic
- US-006 Supporting aggregates for relationships
- MongoDB TestContainers setup
- Spring Data MongoDB configuration

### Risks
- **Risk**: MongoDB document mapping complexity
  **Mitigation**: Comprehensive testing and clear separation of concerns

- **Risk**: Performance issues with large datasets
  **Mitigation**: Indexing strategy and query optimization

- **Risk**: Transaction support implementation
  **Mitigation**: Design repositories with transaction readiness

## Testing Strategy

### Unit Testing
- Repository interface contract verification
- Document mapping accuracy
- Error handling scenarios
- Edge cases and boundary conditions

### Integration Testing
- Full repository operations with TestContainers
- Spring configuration validation
- Performance benchmarking
- Transaction preparation testing

### Test Data Requirements
- Valid question aggregates for all types
- Complex relationship scenarios
- Error condition test cases
- Performance test datasets

## Technical Notes

### Design Patterns Used
- **Repository Pattern**: Core data access abstraction
- **Data Mapper Pattern**: Aggregate-document conversion
- **Result Pattern**: Consistent error handling

### Performance Considerations
- Efficient MongoDB queries with proper indexing
- Bulk operations for relationship management
- Connection pooling optimization
- Query result caching where appropriate

### Security Considerations
- User and question bank scoping in all queries
- Input validation in repository methods
- No direct database access bypass domain rules